#Conductance based

# Required libraries
library(ggplot2)
library(Matrix)

# ============================================================
# PARAMETERS
# ============================================================

# Simulation parameters
dt <- 0.1  # time step (ms)
t_sim <- 1000  # simulation time (ms)
time <- seq(0, t_sim, dt)
n_steps <- length(time)

# Neuron populations
n_sensory <- 5   # number of sensory neurons
n_motor <- 5      # number of motor neurons

lif_params <- list(
    C_m = 1.0, g_L = 0.1, E_L = -70, V_th = -55, V_reset = -75, tau_ref = 2.0,
    E_exc = 0, E_inh = -80,
    tau_syn_exc = 5.0, tau_syn_inh = 8.0,
    g_peak_exc = 0.005, g_peak_inh = 0.007,
    delay_syn = 1.5,
 
    # Noise controls
    use_noise        = TRUE,         # master switch
    noise_model      = "OU",         # "white" or "OU"
    sigma_I_white    = 0.10,         # nA / sqrt(ms)
    sigma_I_ou       = 0.15,         # nA (steady-state SD)
    tau_I_ou         = 5.0,          # ms
    use_channel_noise = TRUE,
    sigma_gL_frac     = 0.05,        # fractional SD of g_L
    tau_gL            = 10.0         # ms
)

sim_modes <- list(sensory_drive = "poisson")

# Parameters for generate_sensory_stimulus() and calculate_reflex_latency()
stim_params <- list(
    start_time = 200,   # ms
    duration   = 50,    # ms
    intensity  = 5000.0,   # arbitrary units for your gain mapping
    noise_std  = 0.05   # stimulus noise SD
)

# ============================================================
# INHOMOGENEOUS POISSON HELPERS (sensory spike generator)
# ============================================================

# generate a Poisson spike train at resolution dt (ms), returning a logical vector of spikes (>=1 event in a bin -> TRUE)
poisson_from_rate <- function(rate_hz, dt) {
    # probability of >=1 event in a bin of width dt (exact Poisson)
    p <- 1 - exp(-pmax(0, rate_hz) * (dt / 1000))
    as.logical(rbinom(length(rate_hz), size = 1, prob = p))
}

# Transformation of analog stimulus into per-neuron time-varying rates, then sample spikes
generate_sensory_spikes_inhom <- function(time, stim_params, n_neurons, dt,
                                          base_rate = 5,    # Hz, background
                                          gain_hz  = 25,    # Hz per stimulus unit
                                          max_rate = 300) { # Hz, safety ceiling

    stim_mat <- generate_sensory_stimulus(time, stim_params, n_neurons)
 
    n_steps <- ncol(stim_mat)
    spikes  <- matrix(FALSE, n_neurons, n_steps)
 
    for (i in 1:n_neurons) {
        # Map stimulus -> instantaneous rate (Hz)
        rate <- base_rate + gain_hz * stim_mat[i, ]
        rate <- pmin(max_rate, pmax(0, rate))  # clip and floor
        spikes[i, ] <- poisson_from_rate(rate, dt)
    }
 
    list(spikes = spikes, rate_hz = NULL)  # (return rates if you want to inspect)
}

# =========================
# Noise helpers
# =========================

# One Euler–Maruyama step of OU process with steady-state SD "sigma_ss"
ou_step <- function(x, tau_ms, sigma_ss, dt) {
    if (tau_ms <= 0) return(0)
    x + (-x / tau_ms) * dt + sqrt(2 * (sigma_ss^2) / tau_ms) * sqrt(dt) * rnorm(1)
}

# Draw white current noise for this step: N(0, sigma * sqrt(dt))
white_I_noise <- function(sigma_I_white, dt) {
    if (sigma_I_white <= 0) return(0)
    sigma_I_white * sqrt(dt) * rnorm(1)
}


# ============================================================
# SPIKE GENERATION AND NEURAL NETWORK SIMULATION
# ============================================================

simulate_reflex_network <- function() {
  cat("Generating sensory stimulus...\n")
  sensory_stimulus <- generate_sensory_stimulus(time, stim_params, n_sensory)

  # Sensory neurons 
  sensory_neurons <- vector("list", n_sensory)
  if (sim_modes$sensory_drive == "poisson") {
    sens_poiss <- generate_sensory_spikes_inhom(time, stim_params, n_sensory, dt,
                                                base_rate = 5, gain_hz = 25, max_rate = 300)
    for (i in seq_len(n_sensory)) {
      sensory_neurons[[i]] <- list(V = rep(NA_real_, n_steps),
                                   spikes = as.logical(sens_poiss$spikes[i, ]))
    }
  }

  cat("Building conductance-based synapses to motor neurons...\n")

  # Connectivity + drive to motor pool
  S <- do.call(rbind, lapply(sensory_neurons, function(x) as.logical(x$spikes)))

  tau  <- lif_params$tau_syn_exc
  gpk  <- lif_params$g_peak_exc
  klen <- max(1L, ceiling(5 * tau / dt))
  tvec <- (0:klen) * dt
  alpha <- (tvec / tau) * exp(1 - tvec / tau)
  delay_steps <- max(0L, round(lif_params$delay_syn / dt))
  kernel <- c(rep(0, delay_steps), gpk * alpha)

  row_conv <- function(row, k) {
    z <- convolve(as.integer(row), rev(k), type = "open")
    as.numeric(z[seq_len(n_steps)])
  }
  G <- t(apply(S, 1L, row_conv, k = kernel))         # [n_sensory x n_steps]

 # Sparse random connectivity/weights W: [n_motor x n_sensory] ---
p_conn <- 0.7
W <- Matrix::rsparsematrix(n_motor, n_sensory, density = p_conn)

# Make weights dimensionless around 1 (±30%), NOT scaled by g_peak_exc
if (length(W@x)) {
  W@x <- runif(length(W@x), 0.7, 1.3)
}


  motor_g_exc <- as.matrix(W %*% G)                  # [n_motor x n_steps]

  cat("Simulating motor neurons (conductance-based inputs)...\n")
  simulate_motor_pool_vec <- function(g_exc_mat, dt, params) {
    n_neurons <- nrow(g_exc_mat); n_steps <- ncol(g_exc_mat)
    V      <- matrix(params$E_L, n_neurons, n_steps)
    spikes <- matrix(FALSE,      n_neurons, n_steps)
    t_last <- rep(-Inf, n_neurons)
    I_no   <- numeric(n_neurons)
    gL_fac <- numeric(n_neurons)

    for (t in 2:n_steps) {
      current_time <- (t - 1) * dt
      in_ref <- (current_time - t_last) <= params$tau_ref

      g_L_t <- rep(params$g_L, n_neurons)
      if (isTRUE(params$use_noise) && isTRUE(params$use_channel_noise)) {
        gL_fac <- gL_fac + (-gL_fac / params$tau_gL) * dt +
          sqrt(2 * (params$sigma_gL_frac^2) / params$tau_gL) * sqrt(dt) * rnorm(n_neurons)
        g_L_t  <- params$g_L * pmax(0, 1 + gL_fac)
      }

      I_noise <- numeric(n_neurons)
      if (isTRUE(params$use_noise)) {
        if (identical(params$noise_model, "white")) {
          I_noise <- params$sigma_I_white * sqrt(dt) * rnorm(n_neurons)
        } else if (identical(params$noise_model, "OU")) {
          I_no <- I_no + (-I_no / params$tau_I_ou) * dt +
            sqrt(2 * (params$sigma_I_ou^2) / params$tau_I_ou) * sqrt(dt) * rnorm(n_neurons)
          I_noise <- I_no
        }
      }

      Vprev  <- V[, t - 1]
      I_leak <- g_L_t              * (params$E_L  - Vprev)
      I_excC <- g_exc_mat[, t - 1] * (params$E_exc - Vprev)
      I_tot  <- I_leak + I_excC + I_noise

      dV <- (I_tot / params$C_m) * dt
      V_new <- Vprev
      V_new[!in_ref] <- Vprev[!in_ref] + dV[!in_ref]
      V[, t] <- V_new

      fired <- (V_new >= params$V_th) & !in_ref
      if (any(fired)) {
        spikes[fired, t] <- TRUE
        V[fired, t]      <- params$V_reset
        t_last[fired]    <- current_time
      }
      V[in_ref, t] <- params$V_reset
    }
    list(V = V, spikes = spikes)
  }

  pool <- simulate_motor_pool_vec(motor_g_exc, dt, lif_params)

  motor_neurons <- vector("list", n_motor)
  for (j in seq_len(n_motor)) {
    motor_neurons[[j]] <- list(V = pool$V[j, ], spikes = as.logical(pool$spikes[j, ]))
  }

  return(list(
    sensory = sensory_neurons,
    motor   = motor_neurons,
    sensory_stimulus = sensory_stimulus,
    motor_g_exc = motor_g_exc,
    time = time
  ))
}


# ============================================================
# LATENCY CALCULATION
# ============================================================

calculate_reflex_latency <- function(motor_response, time) {
    # Find stimulus onset
    stim_onset <- stim_params$start_time
 
    # Detection of threshold firing crossing 
    baseline <- mean(motor_response[time < stim_onset])
    threshold <- baseline + 2 * sd(motor_response[time < stim_onset])
 
    response_idx <- which(motor_response > threshold & time > stim_onset)[1]
 
    if (is.na(response_idx)) {
        return(NA)
    }
 
    latency <- time[response_idx] - stim_onset
    return(latency)
}

# ============================================================
# kNN Mutual Information (KSG) 
# Uses Chebyshev (L_inf) distances as in the original paper.
# Handles ties by adding a tiny jitter to x,y (safe for count data).
# ============================================================
mi_knn_ksg_bits <- function(x, y, k = 5L, jitter_factor = 1e-8, seed = NULL,
                            metric = c("chebyshev", "euclidean")) {
    metric <- match.arg(metric)
    stopifnot(length(x) == length(y))
    N <- length(x)
    if (N <= k + 1L) return(NA_real_)
 
    # Make numeric; add tiny jitter to break ties 
    if (!is.null(seed)) set.seed(seed)
    x <- as.numeric(x); y <- as.numeric(y)
    if (jitter_factor > 0) {
        sx <- sd(x); sy <- sd(y)
        jx <- ifelse(is.finite(sx) && sx > 0, sx * jitter_factor, jitter_factor)
        jy <- ifelse(is.finite(sy) && sy > 0, sy * jitter_factor, jitter_factor)
        x <- x + rnorm(N, 0, jx)
        y <- y + rnorm(N, 0, jy)
    }
 
    # Pairwise distances
    dx <- abs(outer(x, x, "-"))
    dy <- abs(outer(y, y, "-"))
    if (metric == "chebyshev") {
        D <- pmax(dx, dy)
    } else {
        D <- sqrt(dx^2 + dy^2)
    }
    diag(D) <- Inf  # exclude self
 
    # k-th neighbor radii (eps_i)
    # (strict inequality used later; subtract a tiny eps to avoid tie issues)
    k_th <- apply(D, 1L, function(row) sort(row, partial = k)[k])
    eps  <- pmax(k_th - .Machine$double.eps^0.75, 0)
 
    # Counts in marginal projections within eps_i (strict "< eps_i"), self excluded
    # We need per-row thresholds; loop is simplest & fast for N~10^2-10^3
    diag(dx) <- Inf
    diag(dy) <- Inf
    nx <- integer(N)
    ny <- integer(N)
    for (i in seq_len(N)) {
        nx[i] <- sum(dx[i, ] < eps[i])
        ny[i] <- sum(dy[i, ] < eps[i])
    }
 
    # KSG estimator (variant 1): I = ψ(k) + ψ(N) - mean[ ψ(nx+1) + ψ(ny+1) ]
    psi <- digamma
    I_nats <- psi(k) + psi(N) - mean(psi(nx + 1L) + psi(ny + 1L))
    I_bits <- I_nats / log(2)
    max(0, I_bits)
}

# ============================================================
# Bias-corrected MI via trial-shuffle baseline using KSG
# Returns list(mi_knn = raw bits, mi_knn_bc = bias-corrected bits, mi_shuffle_mean)
# ============================================================
mi_knn_bias_corrected <- function(x, y, k = 5L, n_shuffles = 100L,
                                  jitter_factor = 1e-8, metric = "chebyshev") {
    mi_raw <- mi_knn_ksg_bits(x, y, k = k, jitter_factor = jitter_factor, metric = metric)
    if (!is.finite(mi_raw) || is.na(mi_raw) || n_shuffles <= 0L) {
        return(list(mi_knn = mi_raw, mi_knn_bc = mi_raw, mi_shuffle_mean = 0))
    }
    N <- length(x)
    if (N <= k + 1L) {
        return(list(mi_knn = NA_real_, mi_knn_bc = NA_real_, mi_shuffle_mean = NA_real_))
    }
 
    mi_shufs <- numeric(n_shuffles)
    for (s in seq_len(n_shuffles)) {
        y_perm <- sample(y, replace = FALSE)
        mi_shufs[s] <- mi_knn_ksg_bits(x, y_perm, k = k, jitter_factor = jitter_factor, metric = metric)
    }
    shuf_mean <- mean(mi_shufs[is.finite(mi_shufs)], na.rm = TRUE)
    mi_bc <- max(0, mi_raw - shuf_mean)
    list(mi_knn = mi_raw, mi_knn_bc = mi_bc, mi_shuffle_mean = shuf_mean)
}

# Helper to bin population spike counts (sensory & motor) 
bin_population_counts <- function(results, bin_ms = 10, dt = 0.1) {
    stopifnot(is.list(results), !is.null(results$time))
    n_steps   <- length(results$time)
    bin_steps <- max(1L, round(bin_ms / dt))
    n_bins    <- floor(n_steps / bin_steps)
    if (n_bins < 1L) stop("bin_ms too large for the simulation length.")
 
    # turn a list of neurons with $spikes (logical) into binned population counts
    to_binned <- function(neuron_list) {
        # matrix [n_steps x n_neurons] of 0/1 spikes
        M <- sapply(neuron_list, function(cell) as.integer(cell$spikes))
        if (!is.matrix(M)) M <- matrix(M, nrow = n_steps)
        # drop trailing steps to align bins exactly
        M <- M[seq_len(n_bins * bin_steps), , drop = FALSE]
        # population count per time step, then sum within bins
        pop_ts <- rowSums(M)
        dim(pop_ts) <- c(bin_steps, n_bins)   # reshape to [steps_per_bin x n_bins]
        as.integer(colSums(pop_ts))           # one integer count per bin
    }
 
    list(
        sensory_binned = to_binned(results$sensory),
        motor_binned   = to_binned(results$motor),
        n_bins         = as.integer(n_bins),
        bin_steps      = as.integer(bin_steps),
        bin_ms         = bin_ms,
        dt             = dt
    )
}


# ============================================================
# INFORMATION METRICS (KSG kNN estimator + shuffle baseline)
# ============================================================
calculate_information_metrics <- function(results,
                                          bin_ms = 10,
                                          dt = dt,
                                          n_shuffles = 100L,
                                          knn_k = 5L,
                                          knn_metric = c("chebyshev", "euclidean"),
                                          knn_jitter_factor = 1e-8) {
    knn_metric <- match.arg(knn_metric)
    cat("Calculating information metrics (KSG kNN + shuffle correction)…\n")
 
    # Firing stats (whole trial)
    sensory_spikes <- sapply(results$sensory, function(x) sum(x$spikes))
    motor_spikes   <- sapply(results$motor,   function(x) sum(x$spikes))
    sensory_rates  <- sensory_spikes / (t_sim / 1000)
    motor_rates    <- motor_spikes   / (t_sim / 1000)
 
    # Bin population counts
    binned <- bin_population_counts(results, bin_ms = bin_ms, dt = dt)
    if (binned$n_bins < (knn_k + 2L)) {
        warning("Not enough bins for kNN MI; reduce bin_ms or k.")
        return(list(
            sensory_rates = sensory_rates,
            motor_rates   = motor_rates,
            mutual_information_per_bin_plugin   = NA_real_,
            mutual_information_per_bin_MM       = NA_real_,
            mutual_information_per_bin_BC       = NA_real_,  # downstream expects this name
            mutual_information_rate_BC          = NA_real_,
            mutual_information_per_bin_KNN      = NA_real_,
            mutual_information_per_bin_KNN_BC   = NA_real_,
            mi_shuffle_mean                     = NA_real_,
            total_sensory_spikes = sum(sensory_spikes),
            total_motor_spikes   = sum(motor_spikes),
            n_bins = binned$n_bins,
            sensory_binned = binned$sensory_binned,
            motor_binned   = binned$motor_binned
        ))
    }
 
    # KSG kNN MI (bits/bin) + shuffle-baseline bias correction ----
    knn_out <- mi_knn_bias_corrected(
        binned$sensory_binned,
        binned$motor_binned,
        k = knn_k,
        n_shuffles = n_shuffles,
        jitter_factor = knn_jitter_factor,
        metric = knn_metric
    )
 
    # Convert per-bin MI to bits/s
    mi_rate_bc <- knn_out$mi_knn_bc * (1000 / bin_ms)
 
    list(
        sensory_rates = sensory_rates,
        motor_rates   = motor_rates,
 
        mutual_information_per_bin_BC       = knn_out$mi_knn_bc,
        mutual_information_rate_BC          = mi_rate_bc,
 
        # Expose explicit KNN fields
        mutual_information_per_bin_KNN      = knn_out$mi_knn,
        mutual_information_per_bin_KNN_BC   = knn_out$mi_knn_bc,
        mi_shuffle_mean                     = knn_out$mi_shuffle_mean,
 
        total_sensory_spikes = sum(sensory_spikes),
        total_motor_spikes   = sum(motor_spikes),
        n_bins               = binned$n_bins,
        sensory_binned       = binned$sensory_binned,
        motor_binned         = binned$motor_binned
    )
}

# ============================================================
# Cross-trial MI lag scan (population rate code)
# ============================================================

# Helper: stack trialwise binned counts into matrices [n_trials x n_bins]
.stack_trials_to_mats <- function(sens_list, motor_list) {
    # ensure equal lengths across trials (trim to min length)
    lens <- vapply(sens_list, length, integer(1))
    lenm <- vapply(motor_list, length, integer(1))
    nb <- min(min(lens), min(lenm))
    S <- do.call(rbind, lapply(sens_list, function(v) as.integer(v[seq_len(nb)])))
    M <- do.call(rbind, lapply(motor_list, function(v) as.integer(v[seq_len(nb)])))
    list(S = S, M = M, n_bins = nb)
}

# Helper: pair S and M across a given lag (in bins), concatenated over trials
.pair_for_lag <- function(S, M, lag_bins) {
    nb <- ncol(S)
    if (lag_bins >= 0) {
        idx_s <- 1:(nb - lag_bins)
        idx_m <- (1 + lag_bins):nb
    } else {
        k <- -lag_bins
        idx_s <- (1 + k):nb
        idx_m <- 1:(nb - k)
    }
    if (length(idx_s) < 2) return(list(x = integer(0), y = integer(0)))
    x <- as.vector(S[, idx_s, drop = FALSE])
    y <- as.vector(M[, idx_m, drop = FALSE])
    list(x = x, y = y)
}

# Main: MI-vs-lag with plugin, MM and shuffle-baseline bias correction
mi_lag_scan_across_trials <- function(S_trials, M_trials,
                                      bin_ms,
                                      lags_ms = seq(-50, 50, by = bin_ms),
                                      n_shuffles = 200L,
                                      shuffle_mode = c("trial")) {
    shuffle_mode <- match.arg(shuffle_mode)
 
    if (!is.matrix(S_trials) || !is.matrix(M_trials))
        stop("S_trials and M_trials must be matrices [n_trials x n_bins]")
 
    nb <- ncol(S_trials)
    if (nb < 3) stop("Not enough bins to compute lag scan.")
 
    lags_bins <- round(lags_ms / bin_ms)
    out <- data.frame(
        lag_ms = lags_ms,
        mi_plugin_SM = NA_real_,
        mi_MM_SM     = NA_real_,
        mi_BC_SM     = NA_real_,
        shuf_mean_SM = NA_real_,
        mi_plugin_MS = NA_real_,
        mi_MM_MS     = NA_real_,
        mi_BC_MS     = NA_real_,
        shuf_mean_MS = NA_real_
    )
 
    ntr <- nrow(S_trials)
 
    for (i in seq_along(lags_bins)) {
        L <- lags_bins[i]
 
        # Stimulus->Response (S leads, M lags by +L)
        pair_SM <- .pair_for_lag(S_trials, M_trials, L)
        # Response->Stimulus (reverse direction)
        pair_MS <- .pair_for_lag(M_trials, S_trials, L)
 
        # If not enough data at this lag, skip
        if (length(pair_SM$x) < 10L || length(pair_MS$x) < 10L) next
 
        # Plugin & MM for both directions
        JT_SM <- table(pair_SM$x, pair_SM$y)
        JT_MS <- table(pair_MS$x, pair_MS$y)
 
        mi_pl_SM <- entropy::mi.empirical(JT_SM, unit = "log2")
        mi_mm_SM <- mi_MillerMadow(JT_SM)
 
        mi_pl_MS <- entropy::mi.empirical(JT_MS, unit = "log2")
        mi_mm_MS <- mi_MillerMadow(JT_MS)
 
        # Shuffle-baseline (trial permutation of the "response" side)
        if (n_shuffles > 0L) {
            mi_shuf_SM <- numeric(n_shuffles)
            mi_shuf_MS <- numeric(n_shuffles)
 
            for (s in seq_len(n_shuffles)) {
                perm <- sample.int(ntr)
 
                # Build permuted matrices
                M_perm <- M_trials[perm, , drop = FALSE]
                S_perm <- S_trials[perm, , drop = FALSE]
 
                # Re-pair under the same lag
                pSMs <- .pair_for_lag(S_trials, M_perm, L)
                pMSs <- .pair_for_lag(M_trials, S_perm, L)
 
                if (length(pSMs$x) >= 10L)
                    mi_shuf_SM[s] <- mi_MillerMadow(table(pSMs$x, pSMs$y))
                else
                    mi_shuf_SM[s] <- 0
 
                if (length(pMSs$x) >= 10L)
                    mi_shuf_MS[s] <- mi_MillerMadow(table(pMSs$x, pMSs$y))
                else
                    mi_shuf_MS[s] <- 0
            }
 
            shuf_SM <- mean(mi_shuf_SM)
            shuf_MS <- mean(mi_shuf_MS)
 
            mi_bc_SM <- max(0, mi_mm_SM - shuf_SM)
            mi_bc_MS <- max(0, mi_mm_MS - shuf_MS)
        } else {
            shuf_SM <- 0; shuf_MS <- 0
            mi_bc_SM <- mi_mm_SM; mi_bc_MS <- mi_mm_MS
        }
 
        out$mi_plugin_SM[i] <- mi_pl_SM
        out$mi_MM_SM[i]     <- mi_mm_SM
        out$mi_BC_SM[i]     <- mi_bc_SM
        out$shuf_mean_SM[i] <- shuf_SM
 
        out$mi_plugin_MS[i] <- mi_pl_MS
        out$mi_MM_MS[i]     <- mi_mm_MS
        out$mi_BC_MS[i]     <- mi_bc_MS
        out$shuf_mean_MS[i] <- shuf_MS
    }
 
    # Also provide bits/s (optional): multiply by 1000/bin_ms if you want a rate
    out$mi_BC_SM_bits_per_s <- out$mi_BC_SM * (1000 / bin_ms)
    out$mi_BC_MS_bits_per_s <- out$mi_BC_MS * (1000 / bin_ms)
    out
}

# ============================================================
# PROCESSING SPEED CALCULATION
# ============================================================

calculate_processing_speed <- function(latency_ms, mi_per_bin, n_bins) {
    if (is.na(latency_ms) || latency_ms <= 0 ||
        is.na(mi_per_bin) || is.na(n_bins) || n_bins <= 0) return(NA_real_)
    mi_total_bits <- mi_per_bin * n_bins     # total bits over the analyzed window
    (mi_total_bits) / ((latency_ms + 0.75)/1000)       # bits per second. The 0.75 ms serves as a representation of the motor neuron to the
}
# ============================================================

# Minimal stimulus helper
generate_sensory_stimulus <- function(time, stim_params, n_neurons) {
  n_steps <- length(time)
  stim <- matrix(0, nrow = n_neurons, ncol = n_steps)
  on <- which(time >= stim_params$start_time &
              time <  (stim_params$start_time + stim_params$duration))
  if (length(on)) {
    for (i in 1:n_neurons) {
      stim[i, on] <- stim_params$intensity +
        rnorm(length(on), mean = 0, sd = stim_params$noise_std)
    }
  }
  stim
}

# Simple plugin + Miller–Madow MI used by your lag scan 
.mi_plugin_from_table <- function(JT) {
  N <- sum(JT)
  if (N == 0) return(0)
  Px  <- rowSums(JT) / N
  Py  <- colSums(JT) / N
  Pxy <- JT / N
  # avoid log(0): only sum where Pxy > 0
  idx <- which(Pxy > 0, arr.ind = TRUE)
  sum(Pxy[idx] * (log(Pxy[idx]) - log(Px[idx[,1]]) - log(Py[idx[,2]]))) / log(2)
}

mi_MillerMadow <- function(JT) {
  N <- sum(JT)
  if (N == 0) return(0)
  mi_pl <- .mi_plugin_from_table(JT)
  # Approx. Miller–Madow bias term for MI in bits:
  kx <- nrow(JT); ky <- ncol(JT)
  mi_pl + ((kx - 1) * (ky - 1)) / (2 * N * log(2))
}

# Wrapper expected when calling mi_bias_corrected()
mi_bias_corrected <- function(x, y, n_shuffles = 0L) {
  JT <- table(x, y)
  list(mi_mm = mi_MillerMadow(JT))
}

# =======================================================
# TRIAL DEFINITION
# =======================================================	
run_reflex_simulation <- function(n_shuffles = 100L, bin_ms = 10) {
  # 1) run the network
  results <- simulate_reflex_network()

  # 2) build a population motor response (spikes per time step)
  M <- sapply(results$motor, function(cell) as.integer(cell$spikes))  # [n_steps x n_motor]
  if (!is.matrix(M)) M <- matrix(M, nrow = length(results$time))
  motor_pop_ts <- rowSums(M)  # one count per time step

  # 3) latency from stimulus onset to first significant rise
  latency <- calculate_reflex_latency(motor_response = motor_pop_ts,
                                      time = results$time)

  # 4) information metrics (includes binned counts)
  info <- calculate_information_metrics(results,
                                        bin_ms = bin_ms,
                                        dt = dt,
                                        n_shuffles = n_shuffles)

  # 5) processing speed (bits/s)
  speed <- calculate_processing_speed(latency_ms = latency,
                                      mi_per_bin = info$mutual_information_per_bin_BC,
                                      n_bins = info$n_bins)

  list(
    latency = latency,
    info_metrics = info,
    processing_speed = speed,
    results = results
  )
}

# ============================================================
# HELPER FOR LOGS
#=============================================================
write_session_info <- function(outdir = "outputs") {
  if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
  si <- sessionInfo()
  saveRDS(si, file.path(outdir, "sessionInfo.rds"))
  capture.output(print(si), file = file.path(outdir, "sessionInfo.txt"))
}

# ============================================================
# MULTI-TRIAL RUNNER WITH AGGREGATES
# ============================================================
run_experiment <- function(n_trials = 50L, n_shuffles = 100L, bin_ms = 10, verbose = TRUE,
                           lag_window_ms = c(-50, 50)) {
on.exit(write_session_info("outputs"), add = TRUE)
    latencies   <- numeric(n_trials)
    mi_bin_bc   <- numeric(n_trials)
    mi_rate_bc  <- numeric(n_trials)
    speeds_bc   <- numeric(n_trials)
 
    # keep trialwise binned counts to do cross-trial MI
    sens_trials_list  <- vector("list", n_trials)
    motor_trials_list <- vector("list", n_trials)
 
    for (k in seq_len(n_trials)) {
        if (verbose) cat(sprintf("\n--- Trial %d/%d ---\n", k, n_trials))
        set.seed(sample.int(.Machine$integer.max, 1))
        out <- run_reflex_simulation(n_shuffles = n_shuffles, bin_ms = bin_ms)
 
        latencies[k]  <- out$latency
        mi_bin_bc[k]  <- out$info_metrics$mutual_information_per_bin_BC
        mi_rate_bc[k] <- out$info_metrics$mutual_information_rate_BC
        speeds_bc[k]  <- out$processing_speed
 
        # collect binned counts
        sens_trials_list[[k]]  <- out$info_metrics$sensory_binned
        motor_trials_list[[k]] <- out$info_metrics$motor_binned
    }
 
    # summary helper
    summ <- function(x) {
        x <- x[is.finite(x)]
        m <- mean(x); s <- sd(x)
        n <- length(x); se <- s / sqrt(max(1, n))
        ci95 <- c(max(0, m - 1.96*se), m + 1.96*se)
        list(mean = m, sd = s, n = n, ci95 = ci95)
    }

    summary <- list(
        latency_ms      = summ(latencies),
        mi_per_bin_BC   = summ(mi_bin_bc),
        mi_rate_BC_bits_per_s = summ(mi_rate_bc),
        processing_speed_BC_bits_per_s = summ(speeds_bc)
    )
 
    # Pretty print (unchanged)
    cat("\n", paste(rep("=", 60), collapse = ""), "\n")
    cat("MULTI-TRIAL SUMMARY (bias-corrected MI)\n")
    cat(paste(rep("=", 60), collapse = ""), "\n")
    prn <- function(name, s, unit="") {
        cat(sprintf("%-28s mean = %.3f%s | sd = %.3f | n = %d | 95%% CI [%.3f, %.3f]\n",
                    name, s$mean, ifelse(unit=="","",paste0(" ",unit)), s$sd, s$n, s$ci95[1], s$ci95[2]))
    }
    prn("Latency (ms)", summary$latency_ms, "ms")
    prn("MI per bin (BC)", summary$mi_per_bin_BC, "bits")
    prn("MI rate (BC)", summary$mi_rate_BC_bits_per_s, "bits/s")
    prn("Processing speed (BC)", summary$processing_speed_BC_bits_per_s, "bits/s")

    # Cross-trial lag scan (Stimulus -> Response and reverse)
    mats <- .stack_trials_to_mats(sens_trials_list, motor_trials_list)
    lags_ms <- seq(lag_window_ms[1], lag_window_ms[2], by = bin_ms)
 
    lag_scan <- mi_lag_scan_across_trials(
        S_trials = mats$S,
        M_trials = mats$M,
        bin_ms   = bin_ms,
        lags_ms  = lags_ms,
        n_shuffles = n_shuffles,
        shuffle_mode = "trial" # keeps within-trial temporal structure
    )
 
   invisible(list(
  trialwise = data.frame(
    trial = seq_len(n_trials),
    latency_ms = latencies,
    mi_per_bin_BC = mi_bin_bc,
    mi_rate_BC_bits_per_s = mi_rate_bc,
    processing_speed_BC_bits_per_s = speeds_bc
  ),
  summary = summary,
  lag_scan = lag_scan,
  binned_trials = list(S = mats$S, M = mats$M, bin_ms = bin_ms)
))
}

# ============================================================
# RUN SIMULATION
# ============================================================

set.seed(1)  # optional, for reproducibility
simulation_results <- run_experiment(
    n_trials = 10,
    n_shuffles = 100,
    bin_ms = 10,
    verbose = TRUE
)

# ============================================================
# Figure Creation (Code A compatible) — Figures 2, 5, 6, 7 only
# ============================================================

if (!dir.exists("outputs")) dir.create("outputs", recursive = TRUE)

# Libraries used for plotting
library(ggplot2)

# -- Run ONE detailed simulation for per-trial traces/rasters/latency, etc.
#    (Code A defines run_reflex_simulation, not run_polysynaptic_reflex_simulation)
one <- run_reflex_simulation(n_shuffles = 100, bin_ms = 10)  # returns results, latency, info_metrics, processing_speed
# (From Code A) :contentReference[oaicite:0]{index=0}

# -------------------------------
# Fig 2 — Stimulus + activity (single trial)
# Panels: stimulus (top), sensory rasters (mid), motor rasters + population (bottom)
# -------------------------------

time_vec <- one$results$time

# stimulus matrix -> long
stim_mat <- one$results$sensory_stimulus
stim_df <- data.frame(
  t = rep(time_vec, each = nrow(stim_mat)),
  neuron = rep(seq_len(nrow(stim_mat)), times = length(time_vec)),
  stim = as.vector(stim_mat)
)

# sensory spikes to (t, neuron) points
sens_list <- one$results$sensory
sens_spike_df <- do.call(rbind, lapply(seq_along(sens_list), function(i){
  sp <- which(sens_list[[i]]$spikes)
  if (length(sp) == 0) return(NULL)
  data.frame(t = time_vec[sp], neuron = i)
}))

# motor spikes + population motor_response
motor_list <- one$results$motor
motor_spike_df <- do.call(rbind, lapply(seq_along(motor_list), function(i){
  sp <- which(motor_list[[i]]$spikes)
  if (length(sp) == 0) return(NULL)
  data.frame(t = time_vec[sp], neuron = i)
}))

# Code A does not export calculate_motor_response(); build motor_pop from spikes as it does internally
# (rowSums of per-step spike counts). :contentReference[oaicite:1]{index=1}
M <- sapply(one$results$motor, function(cell) as.integer(cell$spikes))
if (!is.matrix(M)) M <- matrix(M, nrow = length(time_vec))
motor_pop <- rowSums(M)

# Plots
p2a <- ggplot(stim_df, aes(t, stim)) +
  geom_line() +
  labs(title = "Stimulus (single trial)", x = "Time (ms)", y = "Intensity (a.u.)") +
  theme_bw()

p2b <- ggplot(sens_spike_df, aes(t, neuron)) +
  geom_point(size = 0.4) +
  labs(title = "Sensory spikes (raster)", x = "Time (ms)", y = "Neuron") +
  theme_bw()

p2c <- ggplot() +
  geom_point(data = motor_spike_df, aes(t, neuron), size = 0.4) +
  labs(title = "Motor spikes (raster)", x = "Time (ms)", y = "Neuron") +
  theme_bw()

p2d <- ggplot(data.frame(t = time_vec, mr = motor_pop), aes(t, mr)) +
  geom_line() +
  labs(title = "Motor population activity (unsmoothed count/bin)", x = "Time (ms)", y = "Spikes/bin (a.u.)") +
  theme_bw()

ggsave("outputs/fig2a_stimulus.png", p2a, width = 6, height = 3, dpi = 300)
ggsave("outputs/fig2b_sensory_raster.png", p2b, width = 6, height = 3, dpi = 300)
ggsave("outputs/fig2c_motor_raster.png", p2c, width = 6, height = 3, dpi = 300)
ggsave("outputs/fig2d_motor_population.png", p2d, width = 6, height = 3, dpi = 300)

# -------------------------------
# Fig 5 — Latency quantification (overlay threshold & onset)
# -------------------------------

stim_on <- stim_params$start_time
base_idx <- time_vec < stim_on
baseline <- mean(motor_pop[base_idx])
thr <- baseline + 2 * sd(motor_pop[base_idx])   # match Code A's threshold
resp_idx <- which(motor_pop > thr & time_vec > stim_on)[1]
lat_ms <- if (length(resp_idx)) time_vec[resp_idx] - stim_on else NA_real_

p5 <- ggplot(data.frame(t = time_vec, mr = motor_pop), aes(t, mr)) +
  geom_line() +
  geom_vline(xintercept = stim_on, linetype = 2) +
  geom_hline(yintercept = thr, linetype = 2) +
  { if (!is.na(lat_ms)) geom_vline(xintercept = stim_on + lat_ms, linetype = 3) else NULL } +
  labs(title = sprintf("Latency = %.2f ms", ifelse(is.na(lat_ms), NaN, lat_ms)),
       x = "Time (ms)", y = "Motor pop. (a.u.)") +
  theme_bw()

ggsave("outputs/fig5_latency.png", p5, width = 6, height = 3, dpi = 300)

# -------------------------------
# Fig 6 — Information transfer
# (A) MI vs lag curve (from multi-trial lag_scan)
# (B) MI per-bin and rate (bias-corrected) from one$info_metrics
# -------------------------------

# Ensure we have the multi-trial object (Code A’s run_experiment returns trialwise, summary, lag_scan) :contentReference[oaicite:3]{index=3}
if (!exists("simulation_results")) {
  simulation_results <- run_experiment(n_trials = 30, n_shuffles = 100, bin_ms = 10, verbose = FALSE)
}

# (A) MI vs lag (Sensory → Motor). Column is mi_BC_SM (bits/bin); lag_ms is provided. :contentReference[oaicite:4]{index=4}
lag_tbl <- simulation_results$lag_scan
p6a <- ggplot(lag_tbl, aes(lag_ms, mi_BC_SM)) +
  geom_line() + geom_point(size = 1.2) +
  labs(title = "MI vs lag (Sensory → Motor)", x = "Lag (ms)", y = "MI (bits/bin)") +
  theme_bw()

# (B) Per-bin MI and MI rate from single-trial info_metrics
# Names in Code A: mutual_information_per_bin_BC (bits/bin), mutual_information_rate_BC (bits/s). :contentReference[oaicite:5]{index=5}
info6 <- one$info_metrics
p6b <- ggplot(data.frame(
  metric = c("MI per bin (BC)", "MI rate (BC)"),
  value  = c(info6$mutual_information_per_bin_BC, info6$mutual_information_rate_BC)
), aes(metric, value)) +
  geom_bar(stat = "identity") +
  labs(title = "Information metrics (bias-corrected)", x = "", y = "Value") +
  theme_bw()

ggsave("outputs/fig6a_mi_vs_lag.png", p6a, width = 6, height = 3, dpi = 300)
ggsave("outputs/fig6b_mi_summary.png", p6b, width = 5, height = 3, dpi = 300)

# -------------------------------
# Fig 7 — Processing speed (per trial & CI) + optional latency-speed relationship
# Fields provided by Code A:
#   simulation_results$trialwise (latency_ms, mi_per_bin_BC, mi_rate_BC_bits_per_s, processing_speed_BC_bits_per_s)
#   simulation_results$summary$processing_speed_BC_bits_per_s (mean, sd, n, ci95)  :contentReference[oaicite:6]{index=6}
# -------------------------------

pt <- simulation_results$trialwise
ci <- simulation_results$summary$processing_speed_BC_bits_per_s

p7a <- ggplot(pt, aes(x = trial, y = processing_speed_BC_bits_per_s)) +
  geom_point() +
  geom_hline(yintercept = ci$mean, linetype = 2) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = ci$ci95[1], ymax = ci$ci95[2]),
            alpha = 0.1, inherit.aes = FALSE) +
  labs(title = sprintf("Processing speed per trial (mean %.2f, 95%% CI %.2f–%.2f)",
                       ci$mean, ci$ci95[1], ci$ci95[2]),
       x = "Trial", y = "Bits/s") +
  theme_bw()

# Optional relationship: latency vs speed
if (all(c("latency_ms","processing_speed_BC_bits_per_s") %in% names(pt))) {
  p7b <- ggplot(pt, aes(x = latency_ms, y = processing_speed_BC_bits_per_s)) +
    geom_point() +
    labs(title = "Latency vs processing speed", x = "Latency (ms)", y = "Bits/s") +
    theme_bw()
  ggsave("outputs/fig7b_latency_vs_speed.png", p7b, width = 5, height = 4, dpi = 300)
}

ggsave("outputs/fig7a_speed_per_trial.png", p7a, width = 6, height = 4, dpi = 300)

# Print to device if interactive
print(p2a); print(p2b); print(p2c); print(p2d)
print(p5)
print(p6a); print(p6b)
print(p7a)
if (exists("p7b")) print(p7b)
