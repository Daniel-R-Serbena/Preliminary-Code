#Conductance based

# Required libraries
library(ggplot2)
library(Matrix)

# ============================================================
# PARAMETERS
# ============================================================

# Simulation parameters
dt <- 0.1  # time step (ms)
t_sim <- 1000  # simulation time (ms)
time <- seq(0, t_sim, dt)
n_steps <- length(time)

# Neuron populations
n_sensory <- 50   # number of sensory neurons
n_motor <- 50      # number of motor neurons

# LIF neuron + sim params (base R only)

lif_params <- list(
  # ---- Biophysical core (units: C_m nF, g nS, V mV, time ms) ----
  C_m    = 0.2,   # ~200 pF commonly used for pyramidal/motor-like cells
  g_L    = 10.0,  # ~10 nS with 0.2 nF -> tau_m ~20 ms
  E_L    = -70.0, # rest ~ -65 to -70 mV
  V_th   = -52.0, # threshold ~ -50 to -55 mV
  V_reset= -67.0, # near rest
  tau_ref= 2.0,   # refractory ~2 ms

  # ---- Synaptic reversal potentials ----
  E_exc  = 0.0,   # AMPA/NMDA ~ 0 mV
  E_inh  = -72.0, # GABA_A ~ -70 to -75 mV

  # ---- Synaptic kinetics (alpha-like) ----
  tau_syn_exc = 5.0, # AMPA ~3–8 ms -> 5 ms
  tau_syn_inh = 8.0, # fast GABA_A ~5–10 ms -> 8 ms

  # ---- Peak conductances for single quanta (scaled by spikes and W) ----
  g_peak_exc = 0.30, # ~0.2–0.4 nS -> 0.30 nS
  g_peak_inh = 0.45, # mIPSC ~0.42–0.48 nS -> 0.45 nS

  # ---- Axo-synaptic delay ----
  delay_syn = 0.75,  # modal ~0.75 ms

  # ---- Noise controls (modeling choices) ----
  use_noise         = TRUE,
  noise_model       = "OU",   # "white" or "OU"
  sigma_I_white     = 0.10,
  sigma_I_ou        = 0.15,
  tau_I_ou          = 5.0,
  use_channel_noise = TRUE,
  sigma_gL_frac     = 0.05,
  tau_gL            = 10.0
)

sim_modes <- list(
  sensory_drive = "poisson"
)

# Parameters for generate_sensory_stimulus() and calculate_reflex_latency()
stim_params <- list(
  start_time = 200,  # ms
  duration   = 50,   # ms
  intensity  = 20.0, # mA (within validated 20–150 mA range)
  noise_std  = 0.05  # a.u.
)

lif2_params <- modifyList(lif_params, list(
  # --- geometry/biophysics (effective lumped) ---
  C_s    = 0.15,   # nF  soma capacitance  (~150 pF)
  C_d    = 0.25,   # nF  dendrite capacitance (~250 pF)
  gL_s   = 8.0,    # nS  soma leak
  gL_d   = 12.0,   # nS  dendrite leak
  E_L_s  = lif_params$E_L,
  E_L_d  = lif_params$E_L,
  g_c    = 6.0,    # nS  axial (coupling) conductance dend<->soma

  # spike/reset live at SOMA (reuse V_th, V_reset, tau_ref from lif_params)

  # synaptic routing (fractions of exc conductance)
  frac_exc_to_d = 0.9,  # 90% of excitation hits dendrite
  frac_exc_to_s = 0.1,  # 10% direct to soma

  # optional inhibitory inputs (off by default here)
  use_inh       = FALSE,
  g_inh_scale   = 1.0
))

# ============================================================
# INHOMOGENEOUS POISSON HELPERS (sensory spike generator)
# ============================================================

# generate a Poisson spike train at resolution dt (ms), returning a logical vector of spikes (>=1 event in a bin -> TRUE)
poisson_from_rate <- function(rate_hz, dt) {
    # probability of >=1 event in a bin of width dt (exact Poisson)
    p <- 1 - exp(-pmax(0, rate_hz) * (dt / 1000))
    as.logical(rbinom(length(rate_hz), size = 1, prob = p))
}

# Transformation of analog stimulus into per-neuron time-varying rates, then sample spikes
generate_sensory_spikes_inhom <- function(time, stim_params, n_neurons, dt,
                                          base_rate = 5,    # Hz, background
                                          gain_hz  = 25,    # Hz per stimulus unit
                                          max_rate = 300) { # Hz, safety ceiling

    stim_mat <- generate_sensory_stimulus(time, stim_params, n_neurons)
 
    n_steps <- ncol(stim_mat)
    spikes  <- matrix(FALSE, n_neurons, n_steps)
 
    for (i in 1:n_neurons) {
        # Map stimulus -> instantaneous rate (Hz)
        rate <- base_rate + gain_hz * stim_mat[i, ]
        rate <- pmin(max_rate, pmax(0, rate))  # clip and floor
        spikes[i, ] <- poisson_from_rate(rate, dt)
    }
 
    list(spikes = spikes, rate_hz = NULL)  # (return rates if you want to inspect)
}

# =========================
# Noise helpers
# =========================

# One Euler–Maruyama step of OU process with steady-state SD "sigma_ss"
ou_step <- function(x, tau_ms, sigma_ss, dt) {
    if (tau_ms <= 0) return(0)
    x + (-x / tau_ms) * dt + sqrt(2 * (sigma_ss^2) / tau_ms) * sqrt(dt) * rnorm(1)
}

# Draw white current noise for this step: N(0, sigma * sqrt(dt))
white_I_noise <- function(sigma_I_white, dt) {
    if (sigma_I_white <= 0) return(0)
    sigma_I_white * sqrt(dt) * rnorm(1)
}


# ============================================================
# Two-compartment motor pool simulator (soma + dendrite)
# Inputs:
#   g_exc_mat : [n_motor x n_steps] total excitatory conductance to each motor neuron (nS)
#   dt        : time step (ms)
#   p         : list with fields set in lif2_params above
# Returns:
#   list(Vs, Vd, spikes) with dims [n_motor x n_steps]
# ============================================================
simulate_motor_pool_2comp <- function(g_exc_mat, dt, p) {
  stopifnot(is.matrix(g_exc_mat))
  n_motor <- nrow(g_exc_mat)
  n_steps <- ncol(g_exc_mat)

  # Pull params (fall back to lif_params-style names if present)
  C_s   <- p$C_s;   C_d <- p$C_d
  gL_s  <- p$gL_s;  gL_d <- p$gL_d
  E_L_s <- p$E_L_s; E_L_d <- p$E_L_d
  g_c   <- p$g_c
  V_th  <- if (!is.null(p$V_th)) p$V_th else -52
  V_reset <- if (!is.null(p$V_reset)) p$V_reset else -67
  tau_ref <- if (!is.null(p$tau_ref)) p$tau_ref else 2.0
  E_exc <- if (!is.null(p$E_exc)) p$E_exc else 0.0

  frac_d <- if (!is.null(p$frac_exc_to_d)) p$frac_exc_to_d else 1.0
  frac_s <- if (!is.null(p$frac_exc_to_s)) p$frac_exc_to_s else (1.0 - frac_d)

  # Optional inhibitory inputs switch (off unless provided)
  use_inh <- isTRUE(p$use_inh)
  g_inh_scale <- if (!is.null(p$g_inh_scale)) p$g_inh_scale else 1.0
  E_inh <- if (!is.null(p$E_inh)) p$E_inh else -72.0
  g_inh <- 0 # you can wire an inhibitory matrix here later if you want

  # Noise (keep it simple; you already add input noise elsewhere)
  use_channel_noise <- isTRUE(p$use_channel_noise)
  sigma_gL_frac <- if (!is.null(p$sigma_gL_frac)) p$sigma_gL_frac else 0
  tau_gL <- if (!is.null(p$tau_gL)) p$tau_gL else 10.0

  # State arrays
  Vs <- matrix(p$E_L_s, n_motor, n_steps)  # soma voltage
  Vd <- matrix(p$E_L_d, n_motor, n_steps)  # dendrite voltage
  spikes <- matrix(FALSE, n_motor, n_steps)

  # Refractory counters (in steps)
  ref_left <- integer(n_motor)

  # Channel-noise OU states (fractional perturbation of gL)
  xi_s <- rep(0, n_motor); xi_d <- rep(0, n_motor)

  # Precompute constants
  ref_steps <- max(0L, round(tau_ref / dt))

  for (t in 2:n_steps) {
    # Conductance split
    gE_tot <- g_exc_mat[, t]                 # nS
    gE_s <- frac_s * gE_tot
    gE_d <- frac_d * gE_tot

    # Optional inhibitory conductance (zero by default)
    gI_s <- if (use_inh) g_inh_scale * g_inh else 0
    gI_d <- if (use_inh) g_inh_scale * g_inh else 0

    # Effective leak with slow OU noise (fractional)
    if (use_channel_noise && sigma_gL_frac > 0 && tau_gL > 0) {
      # Euler–Maruyama OU for each neuron (independent)
      xi_s <- xi_s + (-xi_s / tau_gL) * dt + sqrt(2 * (sigma_gL_frac^2) / tau_gL) * sqrt(dt) * rnorm(n_motor)
      xi_d <- xi_d + (-xi_d / tau_gL) * dt + sqrt(2 * (sigma_gL_frac^2) / tau_gL) * sqrt(dt) * rnorm(n_motor)
      gLs <- pmax(0, gL_s * (1 + xi_s))
      gLd <- pmax(0, gL_d * (1 + xi_d))
    } else {
      gLs <- gL_s
      gLd <- gL_d
    }

    # Previous voltages
    Vs_prev <- Vs[, t - 1]
    Vd_prev <- Vd[, t - 1]

    # Refractory handling: hold at reset, decrement counters
    in_ref <- ref_left > 0
    if (any(in_ref)) {
      Vs_prev[in_ref] <- V_reset
      ref_left[in_ref] <- ref_left[in_ref] - 1L
    }

    # Currents (conductance-based) — sign convention: positive current depolarizes
    # Soma: C_s dVs/dt = -gLs(Vs-ELs) - g_c(Vs - Vd) - gE_s(Vs - E_exc) - gI_s(Vs - E_inh)
    I_s <- -gLs * (Vs_prev - E_L_s) - g_c * (Vs_prev - Vd_prev) -
           gE_s * (Vs_prev - E_exc) - gI_s * (Vs_prev - E_inh)

    # Dendrite
    I_d <- -gLd * (Vd_prev - E_L_d) - g_c * (Vd_prev - Vs_prev) -
           gE_d * (Vd_prev - E_exc) - gI_d * (Vd_prev - E_inh)

    # Euler step
Vs_new <- Vs_prev + (dt / C_s) * I_s
Vd_new <- Vd_prev + (dt / C_d) * I_d

# sanitize numerics so we never propagate NA/Inf
bad_s <- !is.finite(Vs_new)
bad_d <- !is.finite(Vd_new)
if (any(bad_s)) Vs_new[bad_s] <- V_reset       # or Vs_prev[bad_s]
if (any(bad_d)) Vd_new[bad_d] <- E_L_d

# Thresholding at soma (only if not in refractory)
fired <- (!in_ref) & (Vs_new >= V_th)
if (any(fired, na.rm = TRUE)) {                # <- note na.rm = TRUE
  spikes[fired, t] <- TRUE
  Vs_new[fired]    <- V_reset
  ref_left[fired]  <- ref_steps
}

Vs[, t] <- Vs_new
Vd[, t] <- Vd_new
  }

  list(Vs = Vs, Vd = Vd, spikes = spikes)
}


# ============================================================
# SPIKE GENERATION AND NEURAL NETWORK SIMULATION
# ============================================================

simulate_reflex_network <- function() {
  cat("Generating sensory stimulus...\n")
  sensory_stimulus <- generate_sensory_stimulus(time, stim_params, n_sensory)

  # Sensory neurons (Poisson drive)
  sensory_neurons <- vector("list", n_sensory)
  if (sim_modes$sensory_drive == "poisson") {
    sens_poiss <- generate_sensory_spikes_inhom(
      time, stim_params, n_sensory, dt,
      base_rate = 5, gain_hz = 25, max_rate = 300
    )
    for (i in seq_len(n_sensory)) {
      sensory_neurons[[i]] <- list(
        V      = rep(NA_real_, n_steps),
        spikes = as.logical(sens_poiss$spikes[i, ])
      )
    }
  }

  cat("Building conductance-based synapses to motor neurons...\n")

  # Binary spike raster S: [n_sensory x n_steps]
  S <- do.call(rbind, lapply(sensory_neurons, function(x) as.logical(x$spikes)))

  # Alpha kernel for AMPA-like excitation
  tau  <- lif_params$tau_syn_exc
  gpk  <- lif_params$g_peak_exc
  klen <- max(1L, ceiling(5 * tau / dt))
  tvec <- (0:klen) * dt
  alpha <- (tvec / tau) * exp(1 - tvec / tau)
  delay_steps <- max(0L, round(lif_params$delay_syn / dt))
  kernel <- c(rep(0, delay_steps), gpk * alpha)

  row_conv <- function(row, k) {
    z <- convolve(as.integer(row), rev(k), type = "open")
    as.numeric(z[seq_len(n_steps)])
  }
  G <- t(apply(S, 1L, row_conv, k = kernel))  # [n_sensory x n_steps]

  # Sparse random connectivity W: [n_motor x n_sensory]
  p_conn <- 0.2
  W <- Matrix::rsparsematrix(n_motor, n_sensory, density = p_conn)
  if (length(W@x)) W@x <- runif(length(W@x), 0.7, 1.3)

  motor_g_exc <- as.matrix(W %*% G)  # [n_motor x n_steps]

  cat("Simulating motor neurons (two-compartment: soma + dendrite)...\n")
  pool2 <- simulate_motor_pool_2comp(motor_g_exc, dt, lif2_params)

  motor_neurons <- vector("list", n_motor)
  for (j in seq_len(n_motor)) {
    motor_neurons[[j]] <- list(
      V      = pool2$Vs[j, ],          # somatic Vm
      Vd     = pool2$Vd[j, ],          # dendritic Vm
      spikes = as.logical(pool2$spikes[j, ])
    )
  }

  return(list(
    sensory = sensory_neurons,
    motor   = motor_neurons,
    sensory_stimulus = sensory_stimulus,
    motor_g_exc = motor_g_exc,
    time = time
  ))
}


# ============================================================
# LATENCY CALCULATION
# ============================================================

calculate_reflex_latency <- function(motor_response, time) {
    # Find stimulus onset
    stim_onset <- stim_params$start_time
 
    # Detection of threshold firing crossing 
    baseline <- mean(motor_response[time < stim_onset])
    threshold <- baseline + 2 * sd(motor_response[time < stim_onset])
 
    response_idx <- which(motor_response > threshold & time > stim_onset)[1]
 
    if (is.na(response_idx)) {
        return(NA)
    }
 
    latency <- time[response_idx] - stim_onset
    return(latency)
}

# ============================================================
# kNN Mutual Information (KSG) 
# Uses Chebyshev (L_inf) distances as in the original paper.
# Handles ties by adding a tiny jitter to x,y (safe for count data).
# ============================================================
mi_knn_ksg_bits <- function(x, y, k = 5L, jitter_factor = 1e-8, seed = NULL,
                            metric = c("chebyshev", "euclidean")) {
    metric <- match.arg(metric)
    stopifnot(length(x) == length(y))
    N <- length(x)
    if (N <= k + 1L) return(NA_real_)
 
    # Make numeric; add tiny jitter to break ties 
    if (!is.null(seed)) set.seed(seed)
    x <- as.numeric(x); y <- as.numeric(y)
    if (jitter_factor > 0) {
        sx <- sd(x); sy <- sd(y)
        jx <- ifelse(is.finite(sx) && sx > 0, sx * jitter_factor, jitter_factor)
        jy <- ifelse(is.finite(sy) && sy > 0, sy * jitter_factor, jitter_factor)
        x <- x + rnorm(N, 0, jx)
        y <- y + rnorm(N, 0, jy)
    }
 
    # Pairwise distances
    dx <- abs(outer(x, x, "-"))
    dy <- abs(outer(y, y, "-"))
    if (metric == "chebyshev") {
        D <- pmax(dx, dy)
    } else {
        D <- sqrt(dx^2 + dy^2)
    }
    diag(D) <- Inf  # exclude self
 
    # k-th neighbor radii (eps_i)
    # (strict inequality used later; subtract a tiny eps to avoid tie issues)
    k_th <- apply(D, 1L, function(row) sort(row, partial = k)[k])
    eps  <- pmax(k_th - .Machine$double.eps^0.75, 0)
 
    # Counts in marginal projections within eps_i (strict "< eps_i"), self excluded
    # We need per-row thresholds; loop is simplest & fast for N~10^2-10^3
    diag(dx) <- Inf
    diag(dy) <- Inf
    nx <- integer(N)
    ny <- integer(N)
    for (i in seq_len(N)) {
        nx[i] <- sum(dx[i, ] < eps[i])
        ny[i] <- sum(dy[i, ] < eps[i])
    }
 
    # KSG estimator (variant 1): I = ψ(k) + ψ(N) - mean[ ψ(nx+1) + ψ(ny+1) ]
    psi <- digamma
    I_nats <- psi(k) + psi(N) - mean(psi(nx + 1L) + psi(ny + 1L))
    I_bits <- I_nats / log(2)
    max(0, I_bits)
}

# ============================================================
# Bias-corrected MI via trial-shuffle baseline using KSG
# Returns list(mi_knn = raw bits, mi_knn_bc = bias-corrected bits, mi_shuffle_mean)
# ============================================================
mi_knn_bias_corrected <- function(x, y, k = 5L, n_shuffles = 100L,
                                  jitter_factor = 1e-8, metric = "chebyshev") {
    mi_raw <- mi_knn_ksg_bits(x, y, k = k, jitter_factor = jitter_factor, metric = metric)
    if (!is.finite(mi_raw) || is.na(mi_raw) || n_shuffles <= 0L) {
        return(list(mi_knn = mi_raw, mi_knn_bc = mi_raw, mi_shuffle_mean = 0))
    }
    N <- length(x)
    if (N <= k + 1L) {
        return(list(mi_knn = NA_real_, mi_knn_bc = NA_real_, mi_shuffle_mean = NA_real_))
    }
 
    mi_shufs <- numeric(n_shuffles)
    for (s in seq_len(n_shuffles)) {
        y_perm <- sample(y, replace = FALSE)
        mi_shufs[s] <- mi_knn_ksg_bits(x, y_perm, k = k, jitter_factor = jitter_factor, metric = metric)
    }
    shuf_mean <- mean(mi_shufs[is.finite(mi_shufs)], na.rm = TRUE)
    mi_bc <- max(0, mi_raw - shuf_mean)
    list(mi_knn = mi_raw, mi_knn_bc = mi_bc, mi_shuffle_mean = shuf_mean)
}

# Helper to bin population spike counts (sensory & motor) 
bin_population_counts <- function(results, bin_ms = 10, dt = 0.1) {
    stopifnot(is.list(results), !is.null(results$time))
    n_steps   <- length(results$time)
    bin_steps <- max(1L, round(bin_ms / dt))
    n_bins    <- floor(n_steps / bin_steps)
    if (n_bins < 1L) stop("bin_ms too large for the simulation length.")
 
    # turn a list of neurons with $spikes (logical) into binned population counts
    to_binned <- function(neuron_list) {
        # matrix [n_steps x n_neurons] of 0/1 spikes
        M <- sapply(neuron_list, function(cell) as.integer(cell$spikes))
        if (!is.matrix(M)) M <- matrix(M, nrow = n_steps)
        # drop trailing steps to align bins exactly
        M <- M[seq_len(n_bins * bin_steps), , drop = FALSE]
        # population count per time step, then sum within bins
        pop_ts <- rowSums(M)
        dim(pop_ts) <- c(bin_steps, n_bins)   # reshape to [steps_per_bin x n_bins]
        as.integer(colSums(pop_ts))           # one integer count per bin
    }
 
    list(
        sensory_binned = to_binned(results$sensory),
        motor_binned   = to_binned(results$motor),
        n_bins         = as.integer(n_bins),
        bin_steps      = as.integer(bin_steps),
        bin_ms         = bin_ms,
        dt             = dt
    )
}


# ============================================================
# INFORMATION METRICS (KSG kNN estimator + shuffle baseline)
# ============================================================
calculate_information_metrics <- function(results,
                                          bin_ms = 10,
                                          dt = dt,
                                          n_shuffles = 100L,
                                          knn_k = 5L,
                                          knn_metric = c("chebyshev", "euclidean"),
                                          knn_jitter_factor = 1e-8) {
    knn_metric <- match.arg(knn_metric)
    cat("Calculating information metrics (KSG kNN + shuffle correction)…\n")
 
    # Firing stats (whole trial)
    sensory_spikes <- sapply(results$sensory, function(x) sum(x$spikes))
    motor_spikes   <- sapply(results$motor,   function(x) sum(x$spikes))
    sensory_rates  <- sensory_spikes / (t_sim / 1000)
    motor_rates    <- motor_spikes   / (t_sim / 1000)
 
    # Bin population counts
    binned <- bin_population_counts(results, bin_ms = bin_ms, dt = dt)
    if (binned$n_bins < (knn_k + 2L)) {
        warning("Not enough bins for kNN MI; reduce bin_ms or k.")
        return(list(
            sensory_rates = sensory_rates,
            motor_rates   = motor_rates,
            mutual_information_per_bin_plugin   = NA_real_,
            mutual_information_per_bin_MM       = NA_real_,
            mutual_information_per_bin_BC       = NA_real_,  # downstream expects this name
            mutual_information_rate_BC          = NA_real_,
            mutual_information_per_bin_KNN      = NA_real_,
            mutual_information_per_bin_KNN_BC   = NA_real_,
            mi_shuffle_mean                     = NA_real_,
            total_sensory_spikes = sum(sensory_spikes),
            total_motor_spikes   = sum(motor_spikes),
            n_bins = binned$n_bins,
            sensory_binned = binned$sensory_binned,
            motor_binned   = binned$motor_binned
        ))
    }
 
    # KSG kNN MI (bits/bin) + shuffle-baseline bias correction ----
    knn_out <- mi_knn_bias_corrected(
        binned$sensory_binned,
        binned$motor_binned,
        k = knn_k,
        n_shuffles = n_shuffles,
        jitter_factor = knn_jitter_factor,
        metric = knn_metric
    )
 
    # Convert per-bin MI to bits/s
    mi_rate_bc <- knn_out$mi_knn_bc * (1000 / bin_ms)
 
    list(
        sensory_rates = sensory_rates,
        motor_rates   = motor_rates,
 
        mutual_information_per_bin_BC       = knn_out$mi_knn_bc,
        mutual_information_rate_BC          = mi_rate_bc,
 
        # Expose explicit KNN fields
        mutual_information_per_bin_KNN      = knn_out$mi_knn,
        mutual_information_per_bin_KNN_BC   = knn_out$mi_knn_bc,
        mi_shuffle_mean                     = knn_out$mi_shuffle_mean,
 
        total_sensory_spikes = sum(sensory_spikes),
        total_motor_spikes   = sum(motor_spikes),
        n_bins               = binned$n_bins,
        sensory_binned       = binned$sensory_binned,
        motor_binned         = binned$motor_binned
    )
}

# ============================================================
# Cross-trial MI lag scan (population rate code)
# ============================================================

# Helper: stack trialwise binned counts into matrices [n_trials x n_bins]
.stack_trials_to_mats <- function(sens_list, motor_list) {
    # ensure equal lengths across trials (trim to min length)
    lens <- vapply(sens_list, length, integer(1))
    lenm <- vapply(motor_list, length, integer(1))
    nb <- min(min(lens), min(lenm))
    S <- do.call(rbind, lapply(sens_list, function(v) as.integer(v[seq_len(nb)])))
    M <- do.call(rbind, lapply(motor_list, function(v) as.integer(v[seq_len(nb)])))
    list(S = S, M = M, n_bins = nb)
}

# Helper: pair S and M across a given lag (in bins), concatenated over trials
.pair_for_lag <- function(S, M, lag_bins) {
    nb <- ncol(S)
    if (lag_bins >= 0) {
        idx_s <- 1:(nb - lag_bins)
        idx_m <- (1 + lag_bins):nb
    } else {
        k <- -lag_bins
        idx_s <- (1 + k):nb
        idx_m <- 1:(nb - k)
    }
    if (length(idx_s) < 2) return(list(x = integer(0), y = integer(0)))
    x <- as.vector(S[, idx_s, drop = FALSE])
    y <- as.vector(M[, idx_m, drop = FALSE])
    list(x = x, y = y)
}

# Main: MI-vs-lag with plugin, MM and shuffle-baseline bias correction
mi_lag_scan_across_trials <- function(S_trials, M_trials,
                                      bin_ms,
                                      lags_ms = seq(-50, 50, by = bin_ms),
                                      n_shuffles = 200L,
                                      shuffle_mode = c("trial")) {
    shuffle_mode <- match.arg(shuffle_mode)
 
    if (!is.matrix(S_trials) || !is.matrix(M_trials))
        stop("S_trials and M_trials must be matrices [n_trials x n_bins]")
 
    nb <- ncol(S_trials)
    if (nb < 3) stop("Not enough bins to compute lag scan.")
 
    lags_bins <- round(lags_ms / bin_ms)
    out <- data.frame(
        lag_ms = lags_ms,
        mi_plugin_SM = NA_real_,
        mi_MM_SM     = NA_real_,
        mi_BC_SM     = NA_real_,
        shuf_mean_SM = NA_real_,
        mi_plugin_MS = NA_real_,
        mi_MM_MS     = NA_real_,
        mi_BC_MS     = NA_real_,
        shuf_mean_MS = NA_real_
    )
 
    ntr <- nrow(S_trials)
 
    for (i in seq_along(lags_bins)) {
        L <- lags_bins[i]
 
        # Stimulus->Response (S leads, M lags by +L)
        pair_SM <- .pair_for_lag(S_trials, M_trials, L)
        # Response->Stimulus (reverse direction)
        pair_MS <- .pair_for_lag(M_trials, S_trials, L)
 
        # If not enough data at this lag, skip
        if (length(pair_SM$x) < 10L || length(pair_MS$x) < 10L) next
 
        # Plugin & MM for both directions
        JT_SM <- table(pair_SM$x, pair_SM$y)
        JT_MS <- table(pair_MS$x, pair_MS$y)
 
        mi_pl_SM <- entropy::mi.empirical(JT_SM, unit = "log2")
        mi_mm_SM <- mi_MillerMadow(JT_SM)
 
        mi_pl_MS <- entropy::mi.empirical(JT_MS, unit = "log2")
        mi_mm_MS <- mi_MillerMadow(JT_MS)
 
        # Shuffle-baseline (trial permutation of the "response" side)
        if (n_shuffles > 0L) {
            mi_shuf_SM <- numeric(n_shuffles)
            mi_shuf_MS <- numeric(n_shuffles)
 
            for (s in seq_len(n_shuffles)) {
                perm <- sample.int(ntr)
 
                # Build permuted matrices
                M_perm <- M_trials[perm, , drop = FALSE]
                S_perm <- S_trials[perm, , drop = FALSE]
 
                # Re-pair under the same lag
                pSMs <- .pair_for_lag(S_trials, M_perm, L)
                pMSs <- .pair_for_lag(M_trials, S_perm, L)
 
                if (length(pSMs$x) >= 10L)
                    mi_shuf_SM[s] <- mi_MillerMadow(table(pSMs$x, pSMs$y))
                else
                    mi_shuf_SM[s] <- 0
 
                if (length(pMSs$x) >= 10L)
                    mi_shuf_MS[s] <- mi_MillerMadow(table(pMSs$x, pMSs$y))
                else
                    mi_shuf_MS[s] <- 0
            }
 
            shuf_SM <- mean(mi_shuf_SM)
            shuf_MS <- mean(mi_shuf_MS)
 
            mi_bc_SM <- max(0, mi_mm_SM - shuf_SM)
            mi_bc_MS <- max(0, mi_mm_MS - shuf_MS)
        } else {
            shuf_SM <- 0; shuf_MS <- 0
            mi_bc_SM <- mi_mm_SM; mi_bc_MS <- mi_mm_MS
        }
 
        out$mi_plugin_SM[i] <- mi_pl_SM
        out$mi_MM_SM[i]     <- mi_mm_SM
        out$mi_BC_SM[i]     <- mi_bc_SM
        out$shuf_mean_SM[i] <- shuf_SM
 
        out$mi_plugin_MS[i] <- mi_pl_MS
        out$mi_MM_MS[i]     <- mi_mm_MS
        out$mi_BC_MS[i]     <- mi_bc_MS
        out$shuf_mean_MS[i] <- shuf_MS
    }
 
    # Also provide bits/s (optional): multiply by 1000/bin_ms if you want a rate
    out$mi_BC_SM_bits_per_s <- out$mi_BC_SM * (1000 / bin_ms)
    out$mi_BC_MS_bits_per_s <- out$mi_BC_MS * (1000 / bin_ms)
    out
}

# ============================================================
# PROCESSING SPEED CALCULATION
# ============================================================

calculate_processing_speed <- function(latency_ms, mi_per_bin, n_bins) {
    if (is.na(latency_ms) || latency_ms <= 0 ||
        is.na(mi_per_bin) || is.na(n_bins) || n_bins <= 0) return(NA_real_)
    mi_total_bits <- mi_per_bin * n_bins     # total bits over the analyzed window
    (mi_total_bits) / (latency_ms/1000)       # bits per second.
}
# ============================================================

# Minimal stimulus helper
generate_sensory_stimulus <- function(time, stim_params, n_neurons) {
  n_steps <- length(time)
  stim <- matrix(0, nrow = n_neurons, ncol = n_steps)
  on <- which(time >= stim_params$start_time &
              time <  (stim_params$start_time + stim_params$duration))
  if (length(on)) {
    for (i in 1:n_neurons) {
      stim[i, on] <- stim_params$intensity +
        rnorm(length(on), mean = 0, sd = stim_params$noise_std)
    }
  }
  stim
}

# Simple plugin + Miller–Madow MI used by your lag scan 
.mi_plugin_from_table <- function(JT) {
  N <- sum(JT)
  if (N == 0) return(0)
  Px  <- rowSums(JT) / N
  Py  <- colSums(JT) / N
  Pxy <- JT / N
  # avoid log(0): only sum where Pxy > 0
  idx <- which(Pxy > 0, arr.ind = TRUE)
  sum(Pxy[idx] * (log(Pxy[idx]) - log(Px[idx[,1]]) - log(Py[idx[,2]]))) / log(2)
}

mi_MillerMadow <- function(JT) {
  N <- sum(JT)
  if (N == 0) return(0)
  mi_pl <- .mi_plugin_from_table(JT)
  # Approx. Miller–Madow bias term for MI in bits:
  kx <- nrow(JT); ky <- ncol(JT)
  mi_pl + ((kx - 1) * (ky - 1)) / (2 * N * log(2))
}

# Wrapper expected when calling mi_bias_corrected()
mi_bias_corrected <- function(x, y, n_shuffles = 0L) {
  JT <- table(x, y)
  list(mi_mm = mi_MillerMadow(JT))
}

# =======================================================
# TRIAL DEFINITION
# =======================================================	
run_reflex_simulation <- function(n_shuffles = 100L, bin_ms = 10) {
  # 1) run the network
  results <- simulate_reflex_network()

  # 2) build a population motor response (spikes per time step)
  M <- sapply(results$motor, function(cell) as.integer(cell$spikes))  # [n_steps x n_motor]
  if (!is.matrix(M)) M <- matrix(M, nrow = length(results$time))
  motor_pop_ts <- rowSums(M)  # one count per time step

  # 3) latency from stimulus onset to first significant rise
  latency <- calculate_reflex_latency(motor_response = motor_pop_ts,
                                      time = results$time)

  # 4) information metrics (includes binned counts)
  info <- calculate_information_metrics(results,
                                        bin_ms = bin_ms,
                                        dt = dt,
                                        n_shuffles = n_shuffles)

  # 5) processing speed (bits/s)
  speed <- calculate_processing_speed(latency_ms = latency,
                                      mi_per_bin = info$mutual_information_per_bin_BC,
                                      n_bins = info$n_bins)

  list(
    latency = latency,
    info_metrics = info,
    processing_speed = speed,
    results = results
  )
}

# ============================================================
# HELPER FOR LOGS
#=============================================================
write_session_info <- function(outdir = "outputs") {
  if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
  si <- sessionInfo()
  saveRDS(si, file.path(outdir, "sessionInfo.rds"))
  capture.output(print(si), file = file.path(outdir, "sessionInfo.txt"))
}

# ============================================================
# MULTI-TRIAL RUNNER WITH AGGREGATES
# ============================================================
run_experiment <- function(n_trials = 50L, n_shuffles = 100L, bin_ms = 10, verbose = TRUE,
                           lag_window_ms = c(-50, 50)) {
on.exit(write_session_info("outputs"), add = TRUE)
    latencies   <- numeric(n_trials)
    mi_bin_bc   <- numeric(n_trials)
    mi_rate_bc  <- numeric(n_trials)
    speeds_bc   <- numeric(n_trials)
 
    # keep trialwise binned counts to do cross-trial MI
    sens_trials_list  <- vector("list", n_trials)
    motor_trials_list <- vector("list", n_trials)
 
    for (k in seq_len(n_trials)) {
        if (verbose) cat(sprintf("\n--- Trial %d/%d ---\n", k, n_trials))
        set.seed(sample.int(.Machine$integer.max, 1))
        out <- run_reflex_simulation(n_shuffles = n_shuffles, bin_ms = bin_ms)
 
        latencies[k]  <- out$latency
        mi_bin_bc[k]  <- out$info_metrics$mutual_information_per_bin_BC
        mi_rate_bc[k] <- out$info_metrics$mutual_information_rate_BC
        speeds_bc[k]  <- out$processing_speed
 
        # collect binned counts
        sens_trials_list[[k]]  <- out$info_metrics$sensory_binned
        motor_trials_list[[k]] <- out$info_metrics$motor_binned
    }
 
    # summary helper
    summ <- function(x) {
        x <- x[is.finite(x)]
        m <- mean(x); s <- sd(x)
        n <- length(x); se <- s / sqrt(max(1, n))
        ci95 <- c(max(0, m - 1.96*se), m + 1.96*se)
        list(mean = m, sd = s, n = n, ci95 = ci95)
    }

    summary <- list(
        latency_ms      = summ(latencies),
        mi_per_bin_BC   = summ(mi_bin_bc),
        mi_rate_BC_bits_per_s = summ(mi_rate_bc),
        processing_speed_BC_bits_per_s = summ(speeds_bc)
    )
 
    # Pretty print (unchanged)
    cat("\n", paste(rep("=", 60), collapse = ""), "\n")
    cat("MULTI-TRIAL SUMMARY (bias-corrected MI)\n")
    cat(paste(rep("=", 60), collapse = ""), "\n")
    prn <- function(name, s, unit="") {
        cat(sprintf("%-28s mean = %.3f%s | sd = %.3f | n = %d | 95%% CI [%.3f, %.3f]\n",
                    name, s$mean, ifelse(unit=="","",paste0(" ",unit)), s$sd, s$n, s$ci95[1], s$ci95[2]))
    }
    prn("Latency (ms)", summary$latency_ms, "ms")
    prn("MI per bin (BC)", summary$mi_per_bin_BC, "bits")
    prn("MI rate (BC)", summary$mi_rate_BC_bits_per_s, "bits/s")
    prn("Processing speed (BC)", summary$processing_speed_BC_bits_per_s, "bits/s")

    # Cross-trial lag scan (Stimulus -> Response and reverse)
    mats <- .stack_trials_to_mats(sens_trials_list, motor_trials_list)
    lags_ms <- seq(lag_window_ms[1], lag_window_ms[2], by = bin_ms)
 
    lag_scan <- mi_lag_scan_across_trials(
        S_trials = mats$S,
        M_trials = mats$M,
        bin_ms   = bin_ms,
        lags_ms  = lags_ms,
        n_shuffles = n_shuffles,
        shuffle_mode = "trial" # keeps within-trial temporal structure
    )
 
   invisible(list(
  trialwise = data.frame(
    trial = seq_len(n_trials),
    latency_ms = latencies,
    mi_per_bin_BC = mi_bin_bc,
    mi_rate_BC_bits_per_s = mi_rate_bc,
    processing_speed_BC_bits_per_s = speeds_bc
  ),
  summary = summary,
  lag_scan = lag_scan,
  binned_trials = list(S = mats$S, M = mats$M, bin_ms = bin_ms)
))
}

# ============================================================
# RUN SIMULATION
# ============================================================

set.seed(1)  # optional, for reproducibility
simulation_results <- run_experiment(
    n_trials = 10,
    n_shuffles = 100,
    bin_ms = 10,
    verbose = TRUE
)